{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d50e013",
   "metadata": {},
   "source": [
    "# **Subset CONUS and run ParFlow-CLM**\n",
    "Subsetting a small box domain for 1 month to test data assembly workflows for a CONUS2 domain. \n",
    "\n",
    "This is a first cut eventually we need to cover everything in [this outline](https://docs.google.com/document/d/1TNZCPCYj1qsA4OlMlN3NB6XSOuV5fUmY4w4f6O7dm_8/edit?pli=1&tab=t.0) from Reed\n",
    "\n",
    "\n",
    "#### Inputs needed for training: \n",
    "**Transient:** \n",
    "- evap-trans file (trasient) \n",
    "- pressure (starting and labeled)\n",
    "\n",
    "**Static inputs:** \n",
    "- slopes: x & y (2*2D)\n",
    "- Perm: Kx, ky & Kz (3*3D) (we have just need to be added)\n",
    "- Porosity (1*3D) (we have just need to be added)\n",
    "- Van Genuchten (2*3D) (sres, ssat)\n",
    "- Specific Storage (1*3D)\n",
    "- Mannings (1*2D)\n",
    "- Flow barrier? \n",
    "\n",
    "\n",
    "### Questions: \n",
    "- Do we want to generate Perm, Porosity VG and SS once for all of CONUS2 or do them on the fly now for subsets -- I'm thinking generate them once for all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134427aa",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c7594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from parflow import Run\n",
    "from parflow.tools.io import read_pfb, read_clm, write_pfb\n",
    "from parflow.tools.fs import mkdir\n",
    "from parflow.tools.settings import set_working_directory\n",
    "import subsettools as st\n",
    "import hf_hydrodata as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e081a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to register on https://hydrogen.princeton.edu/pin before you can use the hydrodata utilities\n",
    "#email = input('Enter your hydrgen email address')\n",
    "#pin = input('Enter your hydrogen PIN')\n",
    "email='lecondon@email.arizona.edu'\n",
    "pin=1234\n",
    "#print('Registering ' + email + ' (PIN=' + pin + ') for HydroData download' ) #use lecondon@email.arizona.edu and 1234\n",
    "hf.register_api_pin(email, pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec636a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define variables to access datasets in Hydrodata to subset and define write paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c0d79",
   "metadata": {},
   "source": [
    "#### Set your variables to specify which static and climate forcing data you would like to subset in Hydrodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb131aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runname = \"test_box1\"\n",
    "base_dir = os.path.join(\"/Users/laura/Documents/Research/NAIRR\")\n",
    "variable_list=['slope_x', 'slope_y', 'pme', 'ss_pressure_head', 'pf_indicator', 'pf_flowbarrier', 'mannings', 'specific_storage', 'sres' , 'ssat' , 'top_patch', 'porosity', 'permeability_x', 'permeability_y' , 'permeability_z']\n",
    "\n",
    "# provide information about the datasets you want to access for run inputs using the data catalog\n",
    "start = \"2005-10-01\"\n",
    "end = \"2005-10-03\"\n",
    "grid = \"conus2\"\n",
    "var_ds = \"conus2_domain\"\n",
    "\n",
    "# set the directory paths where you want to write your subset files and make directories for static and transient inputs\n",
    "input_dir = os.path.join(base_dir, f\"{runname}_{grid}_{end[:4]}WY\")\n",
    "static_write_dir = os.path.join(input_dir, \"static\")\n",
    "mkdir(static_write_dir)\n",
    "transient_write_dir = os.path.join(input_dir, \"transient\")\n",
    "mkdir(transient_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672812cb",
   "metadata": {},
   "source": [
    "### 2. Get the desired ParFlow i/j bbox from user provided geospatial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d50bbca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box: (1000, 1000, 1064, 1064)\n",
      "nj: 64\n",
      "ni: 64\n",
      "0.0% of the domain is outside the mask\n"
     ]
    }
   ],
   "source": [
    "#Define a box domain using the i,j indices\n",
    "box_size = 64 #assuming a square box \n",
    "lower_left= [1000,1000] # lowerleft corner of the box using i,j indices\n",
    "ij_bounds = tuple([lower_left[0], lower_left[1], lower_left[0]+box_size, lower_left[1]+ box_size])\n",
    "\n",
    "nj = ij_bounds[3] - ij_bounds[1]\n",
    "ni = ij_bounds[2] - ij_bounds[0]\n",
    "print(f\"bounding box: {ij_bounds}\")\n",
    "print(f\"nj: {nj}\")\n",
    "print(f\"ni: {ni}\")\n",
    "\n",
    "# Read the mask file and check what portion of the domain is in the active CONUS2 domain \n",
    "options = {\n",
    "      \"dataset\":\"conus2_domain\", \"variable\": \"mask\",  \"grid_bounds\": ij_bounds\n",
    "}\n",
    "mask = hf.get_gridded_data(options)\n",
    "outside_frac = (np.count_nonzero(np.isnan(mask)))/(box_size*box_size)*100\n",
    "print(str(outside_frac) + '% of the domain is outside the mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da721b9",
   "metadata": {},
   "source": [
    "### 4. Subset ParFlow Files\n",
    "\n",
    "**Note: We either need to get the parameter table and use this to translate the indicator file to the other variables we need or we need to save them out for CONUS2 somewhere. \n",
    "\n",
    "Additional needed variables: \n",
    "- permeability\n",
    "- porosity\n",
    "- VGN Alpha \n",
    "- VGN n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec16ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/jbn7kjwj0vl22h500w7bkfqh0000gn/T/ipykernel_91141/3735172536.py:1: DeprecationWarning: Note that for subsettools versions >= 2.0.0, this function will raise a ValueError if a variable in var_list is not supported in the dataset. (In older versions, it just printed an error message and continued executing normally). You can check in the HydroData documentation which variables are contained in each dataset (https://hf-hydrodata.readthedocs.io/en/latest/available_data.html).\n",
      "  static_paths = st.subset_static(ij_bounds, dataset=var_ds, write_dir=static_write_dir, var_list=variable_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote slope_x.pfb in specified directory.\n",
      "Wrote slope_y.pfb in specified directory.\n",
      "Wrote pme.pfb in specified directory.\n",
      "Wrote ss_pressure_head.pfb in specified directory.\n",
      "Wrote pf_indicator.pfb in specified directory.\n",
      "Wrote pf_flowbarrier.pfb in specified directory.\n",
      "Wrote mannings.pfb in specified directory.\n",
      "Wrote specific_storage.pfb in specified directory.\n",
      "Wrote sres.pfb in specified directory.\n",
      "Wrote ssat.pfb in specified directory.\n",
      "Wrote top_patch.pfb in specified directory.\n",
      "Wrote porosity.pfb in specified directory.\n",
      "Wrote permeability_x.pfb in specified directory.\n",
      "Wrote permeability_y.pfb in specified directory.\n",
      "Wrote permeability_z.pfb in specified directory.\n",
      "(1000, 1000, 1064, 1064)\n"
     ]
    }
   ],
   "source": [
    "static_paths = st.subset_static(ij_bounds, dataset=var_ds, write_dir=static_write_dir, var_list=variable_list)\n",
    "print(ij_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4062d6c",
   "metadata": {},
   "source": [
    "### 4. Subset transient PF pressure files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fa6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "Pressure files downloaded from Hydrodata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laura/miniconda3/envs/hydrogen_emulator/lib/python3.10/site-packages/hf_hydrodata/gridded.py:1573: UserWarning: API timeout, performing retry.\n",
      "  warnings.warn(\"API timeout, performing retry.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Timeout error from server. Try again later or try to reduce the size of data in the API request using time or space filters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#Get the evaptrans files from hydrodata\u001b[39;00m\n\u001b[1;32m     17\u001b[0m options_et \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparflow_evaptrans\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal_resolution\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhourly\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: start_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrid_bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m: ij_bounds, \n\u001b[1;32m     20\u001b[0m }\n\u001b[0;32m---> 21\u001b[0m data_et \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gridded_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions_et\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#hf.get_gridded_files(options)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_et\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/hydrogen_emulator/lib/python3.10/site-packages/hf_hydrodata/gridded.py:1207\u001b[0m, in \u001b[0;36mget_gridded_data\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCW3E\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_version\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m options:\n\u001b[1;32m   1197\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAs of 2024-10-09, version 1.0 of the CW3E dataset has been released. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDue to known improvements in the results, this dataset version is now \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   1206\u001b[0m     )\n\u001b[0;32m-> 1207\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_get_gridded_data_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;66;03m# An optional empty array passed as an option to be populated with the time dimension for graphing.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m time_values \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hydrogen_emulator/lib/python3.10/site-packages/hf_hydrodata/gridded.py:1581\u001b[0m, in \u001b[0;36m_get_gridded_data_from_api\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m502\u001b[39m]:\n\u001b[0;32m-> 1581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout error from server. Try again later or try to reduce the size of data in the API request using time or space filters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1583\u001b[0m     )\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgridded_data_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m returned error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1587\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Timeout error from server. Try again later or try to reduce the size of data in the API request using time or space filters."
     ]
    }
   ],
   "source": [
    "#Get the pressure files for a single month\n",
    "dataset = \"conus2_baseline\"\n",
    "start_date = '2002-10-01'\n",
    "end_date= '2002-10-02'\n",
    "\n",
    "#Get the pressure files from hydrodata\n",
    "options_p = {\n",
    "      \"dataset\": dataset, \"variable\": \"pressure_head\", \"temporal_resolution\": \"hourly\",\n",
    "      \"start_time\": start_date, \"end_time\": end_date, \"grid_bounds\": ij_bounds, \n",
    "}\n",
    "data_p = hf.get_gridded_data(options)\n",
    "#hf.get_gridded_files(options)\n",
    "print(data_p.shape)\n",
    "print('Pressure files downloaded from Hydrodata')\n",
    "\n",
    "#Get the evaptrans files from hydrodata\n",
    "options_et = {\n",
    "      \"dataset\": dataset, \"variable\": \"parflow_evaptrans\", \"temporal_resolution\": \"hourly\",\n",
    "      \"start_time\": start_date, \"end_time\": end_date, \"grid_bounds\": ij_bounds, \n",
    "}\n",
    "data_et = hf.get_gridded_data(options_et)\n",
    "#hf.get_gridded_files(options)\n",
    "print(data_et.shape)\n",
    "print('Evaptrans files downloaded from Hydrodata')\n",
    "\n",
    "#Write out the pressure and evaptrans as pfbs\n",
    "for hour in range(data_p.shape[0]):\n",
    "    file_name=f'{transient_write_dir}/pressure.{str(hour).zfill(5)}.pfb'\n",
    "    write_pfb(file=file_name, array=data_p[hour,:,:,:], dist=False)\n",
    "\n",
    "    file_name=f'{transient_write_dir}/evaptrans.{str(hour).zfill(5)}.pfb'\n",
    "    write_pfb(file=file_name, array=data_et[hour,:,:,:], dist=False)\n",
    "\n",
    "\n",
    "print('Pressure and ET files written to transient directory')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd2020",
   "metadata": {},
   "source": [
    "### 5. Subset transient evaptrans files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the pressure files for a single month\n",
    "dataset = \"conus2_baseline\"\n",
    "variable = \"pressure_head\"\n",
    "start_date = '2003-06-01'\n",
    "end_date= '2003-06-02'\n",
    "\n",
    "options = {\n",
    "      \"dataset\": dataset, \"variable\": \"pressure_head\", \"temporal_resolution\": \"hourly\",\n",
    "      \"start_time\": start_date, \"end_time\": end_date, \"grid_bounds\": ij_bounds, \n",
    "}\n",
    "data = hf.get_gridded_data(options)\n",
    "#hf.get_gridded_files(options)\n",
    "print(data.shape)\n",
    "print('Pressure files downloaded from Hydrodata')\n",
    "\n",
    "for hour in range(data.shape[0]):\n",
    "    file_name=f'{transient_write_dir}/pressure.{str(hour).zfill(5)}.pfb'\n",
    "    write_pfb(file=file_name, array=data[hour,:,:,:], dist=False)\n",
    "print('Pressure files written to transient directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af83af",
   "metadata": {},
   "source": [
    "#### Not used just data catalog searching examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e653b968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conus1_baseline_85', 'conus1_baseline_mod', 'conus1_current_conditions', 'conus2_baseline']\n",
      "['evapotranspiration', 'ground_evap', 'ground_evap_heat', 'ground_heat', 'ground_temp', 'infiltration', 'irrigation', 'latent_heat', 'outward_longwave_radiation', 'pressure_head', 'saturation', 'sensible_heat', 'soil_moisture', 'soil_temp', 'streamflow', 'subsurface_storage', 'surface_water_storage', 'swe', 'transpiration', 'transpiration_leaves', 'water_table_depth']\n",
      "{'id': '558', 'dataset': 'conus2_baseline', 'dataset_version': '', 'file_type': 'pfb', 'variable': 'pressure_head', 'dataset_var': 'press', 'temporal_resolution': 'hourly', 'units': 'm', 'aggregation': '-', 'grid': 'conus2', 'path': 'spinup.wy{wy}.out.press.{wy_hour:05d}.pfb', 'file_grouping': 'wy_hour', 'entry_start_date': '2002-10-01', 'entry_end_date': '2003-09-30', 'documentation_notes': '', 'site_type': '', 'variable_type': 'subsurface', 'has_z': 'TRUE', 'dataset_type': 'parflow', 'datasource': 'hydroframe', 'paper_dois': None, 'dataset_dois': None, 'dataset_start_date': '2002-10-01', 'dataset_end_date': '2003-09-30', 'structure_type': 'gridded', 'has_ensemble': '', 'unit_type': 'length', 'period': 'hourly'}\n",
      "['CW3E', 'NLDAS2', 'NLDAS2_85', 'ameriflux', 'conus1_baseline_85', 'conus1_baseline_mod', 'conus1_current_conditions', 'conus1_domain', 'conus2_baseline', 'conus2_current_conditions', 'conus2_domain', 'fan_2013', 'huc_mapping', 'jasechko_2024', 'modis', 'nasa_smap', 'noaa', 'scan', 'snotel', 'usgs_nwis']\n",
      "['clm_run', 'distance_stream_lin', 'drainage_area', 'elevation', 'flow_direction', 'lat_lon', 'latitude', 'longitude', 'mannings', 'mask', 'pf_flowbarrier', 'pf_indicator', 'pf_solid', 'pme', 'slope_x', 'slope_y', 'ss_pressure_head', 'ss_water_table_depth', 'stream_order', 'stream_segments', 'subbasins', 'veg_type_IGBP']\n"
     ]
    }
   ],
   "source": [
    "#Doing some data catalog searching to pick the pressure files to get\n",
    "datasets = hf.get_datasets(variable = \"pressure_head\")\n",
    "print(datasets)\n",
    "\n",
    "options = {\"dataset\": \"conus2_baseline\", \"grid\": \"conus2\"}\n",
    "variables = hf.get_variables(options)\n",
    "print(variables)\n",
    "\n",
    "options = {\n",
    "   \"dataset\": \"conus2_baseline\", \"variable\": \"pressure_head\",\n",
    "}\n",
    "metadata = hf.get_catalog_entry(options)\n",
    "print(metadata)\n",
    "\n",
    "datasets = hf.get_datasets()\n",
    "print(datasets)\n",
    "\n",
    "options = {\"dataset\": \"conus2_domain\"}\n",
    "variables = hf.get_variables(options)\n",
    "print(variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogen_emulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
