{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d50e013",
   "metadata": {},
   "source": [
    "# **Subset a CONUS2 domain for training and testing**\n",
    "This notebook subsets a rectangular piece of the CONUS2 domain to be used for training and testing the 1-ts emaultor. \n",
    "\n",
    "#### Inputs needed for training: \n",
    "**Transient:** \n",
    "- evaptrans file (trasient) \n",
    "- pressure (starting and labeled)\n",
    "\n",
    "**Static inputs:** \n",
    "- slopes: x & y (2*2D)\n",
    "- Perm: Kx, ky & Kz (3*3D) (we have just need to be added)\n",
    "- Porosity (1*3D) (we have just need to be added)\n",
    "- Van Genuchten (2*3D) (sres, ssat)\n",
    "- Specific Storage (1*3D)\n",
    "- Mannings (1*2D)\n",
    "- Flow barrier? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134427aa",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from parflow import Run\n",
    "from parflow.tools.io import read_pfb, read_clm, write_pfb\n",
    "from parflow.tools.fs import mkdir\n",
    "from parflow.tools.settings import set_working_directory\n",
    "import subsettools as st\n",
    "import hf_hydrodata as hf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e081a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your hydrgen email address lecondon@email.arizona.edu\n",
      "Enter your hydrogen PIN 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering lecondon@email.arizona.edu (PIN=1234) for HydroData download\n"
     ]
    }
   ],
   "source": [
    "# You need to register on https://hydrogen.princeton.edu/pin before you can use the hydrodata utilities\n",
    "email = input('Enter your hydrgen email address')\n",
    "pin = input('Enter your hydrogen PIN')\n",
    "print('Registering ' + email + ' (PIN=' + pin + ') for HydroData download' ) \n",
    "hf.register_api_pin(email, pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec636a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define variables to access datasets in Hydrodata to subset and define write paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb131aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subset name and directory to save it in\n",
    "runname = \"test_CONUS2.1\"\n",
    "#base_dir = os.path.join(\"/Users/laura/Documents/Research/NAIRR\")\n",
    "base_dir = os.path.join(\"/home/lc2465/NAIRR/\")\n",
    "\n",
    "variable_list=['slope_x', 'slope_y', 'pme', 'ss_pressure_head', 'pf_indicator', 'pf_flowbarrier', 'mannings', 'specific_storage', 'sres' , 'ssat' , 'top_patch', 'porosity', 'permeability_x', 'permeability_y' , 'permeability_z']\n",
    "\n",
    "# provide information about the datasets you want to access for run inputs using the data catalog\n",
    "start = \"2002-10-01\"\n",
    "end = \"2002-10-05\"\n",
    "grid = \"conus2\"\n",
    "var_ds = \"conus2_domain\"\n",
    "\n",
    "# set the directory paths and create directories for outputs\n",
    "input_dir = os.path.join(base_dir, f\"{runname}_{grid}_{end[:4]}WY\")\n",
    "static_write_dir = os.path.join(input_dir, \"static\")\n",
    "mkdir(static_write_dir)\n",
    "transient_write_dir = os.path.join(input_dir, \"transient\")\n",
    "mkdir(transient_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672812cb",
   "metadata": {},
   "source": [
    "### 2. Get the desired ParFlow i/j bbox from user provided geospatial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d50bbca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box: (1000, 1000, 1063, 1067)\n",
      "nj: 67\n",
      "ni: 63\n",
      "0.0% of the domain is outside the mask\n"
     ]
    }
   ],
   "source": [
    "#Define a box domain using the i,j indices\n",
    "#box_size = 64 #assuming a square box \n",
    "box_nx = 63\n",
    "box_ny = 67\n",
    "lower_left= [1000,1000] # lowerleft corner of the box using i,j indices\n",
    "\n",
    "ij_bounds = tuple([lower_left[0], lower_left[1], lower_left[0]+box_nx, lower_left[1]+ box_ny])\n",
    "\n",
    "nj = ij_bounds[3] - ij_bounds[1]\n",
    "ni = ij_bounds[2] - ij_bounds[0]\n",
    "print(f\"bounding box: {ij_bounds}\")\n",
    "print(f\"nj: {nj}\")\n",
    "print(f\"ni: {ni}\")\n",
    "\n",
    "# Read the mask file and check what portion of the domain is in the active CONUS2 domain \n",
    "options = {\n",
    "      \"dataset\":\"conus2_domain\", \"variable\": \"mask\",  \"grid_bounds\": ij_bounds\n",
    "}\n",
    "mask = hf.get_gridded_data(options)\n",
    "outside_frac = (np.count_nonzero(np.isnan(mask)))/(box_nx*box_ny)*100\n",
    "print(str(outside_frac) + '% of the domain is outside the mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da721b9",
   "metadata": {},
   "source": [
    "### 4. Subset ParFlow Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec16ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4092762/3446187325.py:1: DeprecationWarning: Note that for subsettools versions >= 2.0.0, this function will raise a ValueError if a variable in var_list is not supported in the dataset. (In older versions, it just printed an error message and continued executing normally). You can check in the HydroData documentation which variables are contained in each dataset (https://hf-hydrodata.readthedocs.io/en/latest/available_data.html).\n",
      "  static_paths = st.subset_static(ij_bounds, dataset=var_ds,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote slope_x.pfb in specified directory.\n",
      "Wrote slope_y.pfb in specified directory.\n",
      "Wrote pme.pfb in specified directory.\n",
      "Wrote ss_pressure_head.pfb in specified directory.\n",
      "Wrote pf_indicator.pfb in specified directory.\n",
      "Wrote pf_flowbarrier.pfb in specified directory.\n",
      "Wrote mannings.pfb in specified directory.\n",
      "Wrote specific_storage.pfb in specified directory.\n",
      "Wrote sres.pfb in specified directory.\n",
      "Wrote ssat.pfb in specified directory.\n",
      "Wrote top_patch.pfb in specified directory.\n",
      "Wrote porosity.pfb in specified directory.\n",
      "Wrote permeability_x.pfb in specified directory.\n",
      "Wrote permeability_y.pfb in specified directory.\n",
      "Wrote permeability_z.pfb in specified directory.\n",
      "(1000, 1000, 1063, 1067)\n"
     ]
    }
   ],
   "source": [
    "static_paths = st.subset_static(ij_bounds, dataset=var_ds,  \n",
    "                                write_dir=static_write_dir, var_list=variable_list)\n",
    "print(ij_bounds)\n",
    "\n",
    "## This is assuming the CONUS2 domain has all the right inputs. \n",
    "## I think this is good for everything except slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4062d6c",
   "metadata": {},
   "source": [
    "### 4. Subset transient PF pressure files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79fa6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressure files downloaded from Hydrodata\n",
      "Shape: (48, 10, 64, 64)\n",
      "Evaptrans files downloaded from Hydrodata\n",
      "shape: (48, 10, 64, 64)\n",
      "Pressure and ET files written to transient directory\n"
     ]
    }
   ],
   "source": [
    "#Get the pressure files for a single month\n",
    "dataset = \"conus2_baseline\"\n",
    "start_date = '2002-10-01'\n",
    "end_date= '2002-10-03'\n",
    "\n",
    "#Get the pressure files from hydrodata\n",
    "options_p = {\n",
    "      \"dataset\": dataset, \"variable\": \"pressure_head\", \"temporal_resolution\": \"hourly\",\n",
    "      \"start_time\": start_date, \"end_time\": end_date, \"grid_bounds\": ij_bounds, \n",
    "}\n",
    "data_p = hf.get_gridded_data(options_p)\n",
    "#hf.get_gridded_files(options)\n",
    "print('Pressure files downloaded from Hydrodata')\n",
    "print('Shape:', data_p.shape)\n",
    "\n",
    "#Get the evaptrans files from hydrodata\n",
    "options_et = {\n",
    "      \"dataset\": dataset, \"variable\": \"parflow_evaptrans\", \"temporal_resolution\": \"hourly\",\n",
    "      \"start_time\": start_date, \"end_time\": end_date, \"grid_bounds\": ij_bounds, \n",
    "}\n",
    "data_et = hf.get_gridded_data(options_et)\n",
    "#hf.get_gridded_files(options)\n",
    "print('Evaptrans files downloaded from Hydrodata')\n",
    "print('shape:', data_et.shape)\n",
    "\n",
    "#Write out the pressure and evaptrans as pfbs\n",
    "for hour in range(data_p.shape[0]):\n",
    "    file_name=f'{transient_write_dir}/pressure.{str(hour).zfill(5)}.pfb'\n",
    "    write_pfb(file=file_name, array=data_p[hour,:,:,:], dist=False)\n",
    "\n",
    "    file_name=f'{transient_write_dir}/evaptrans.{str(hour).zfill(5)}.pfb'\n",
    "    write_pfb(file=file_name, array=data_et[hour,:,:,:], dist=False)\n",
    "\n",
    "print('Pressure and ET files written to transient directory')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af83af",
   "metadata": {},
   "source": [
    "#### Not used just data catalog searching examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e653b968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conus1_baseline_85', 'conus1_baseline_mod', 'conus1_current_conditions', 'conus2_baseline']\n",
      "['evapotranspiration', 'ground_evap', 'ground_evap_heat', 'ground_heat', 'ground_temp', 'infiltration', 'irrigation', 'latent_heat', 'outward_longwave_radiation', 'parflow_evaptrans', 'pressure_head', 'saturation', 'sensible_heat', 'soil_moisture', 'soil_temp', 'streamflow', 'subsurface_storage', 'surface_water_storage', 'swe', 'transpiration', 'transpiration_leaves', 'water_table_depth']\n",
      "{'id': '558', 'dataset': 'conus2_baseline', 'dataset_version': '', 'file_type': 'pfb', 'variable': 'pressure_head', 'dataset_var': 'press', 'entry_start_date': '2002-10-01', 'entry_end_date': '2003-09-30', 'temporal_resolution': 'hourly', 'units': 'm', 'aggregation': '-', 'grid': 'conus2', 'file_grouping': 'wy_hour', 'security_level': '2', 'path': '/hydrodata/temp/CONUS2_transfers/CONUS2/spinup_WY2003/run_inputs/spinup.wy{wy}.out.press.{wy_hour:05d}.pfb', 'documentation_notes': '', 'site_type': '', 'variable_type': 'subsurface', 'has_z': 'TRUE', 'dataset_type': 'parflow', 'datasource': 'hydroframe', 'paper_dois': None, 'dataset_dois': None, 'dataset_start_date': '2002-10-01', 'dataset_end_date': '2003-09-30', 'structure_type': 'gridded', 'has_ensemble': '', 'unit_type': 'length', 'period': 'hourly'}\n",
      "['CW3E', 'NLDAS2', 'NLDAS2_85', 'ameriflux', 'conus1_baseline_85', 'conus1_baseline_mod', 'conus1_current_conditions', 'conus1_domain', 'conus2_baseline', 'conus2_current_conditions', 'conus2_domain', 'fan_2013', 'forecast', 'huc_mapping', 'jasechko_2024', 'ma_2023', 'modis', 'nasa_smap', 'noaa', 'obs_anomalies', 'observations', 'scan', 'scenario', 'snotel', 'usgs_nwis']\n",
      "['clm_run', 'distance_stream_lin', 'drainage_area', 'elevation', 'flow_direction', 'lat_lon', 'latitude', 'longitude', 'mannings', 'mask', 'permeability_x', 'permeability_y', 'permeability_z', 'pf_flowbarrier', 'pf_indicator', 'pf_solid', 'pme', 'porosity', 'slope_x', 'slope_y', 'specific_storage', 'sres', 'ss_pressure_head', 'ss_water_table_depth', 'ssat', 'stream_order', 'stream_segments', 'subbasins', 'top_patch', 'veg_type_IGBP']\n"
     ]
    }
   ],
   "source": [
    "#Doing some data catalog searching to pick the pressure files to get\n",
    "datasets = hf.get_datasets(variable = \"pressure_head\")\n",
    "print(datasets)\n",
    "\n",
    "options = {\"dataset\": \"conus2_baseline\", \"grid\": \"conus2\"}\n",
    "variables = hf.get_variables(options)\n",
    "print(variables)\n",
    "\n",
    "options = {\n",
    "   \"dataset\": \"conus2_baseline\", \"variable\": \"pressure_head\",\n",
    "}\n",
    "metadata = hf.get_catalog_entry(options)\n",
    "print(metadata)\n",
    "\n",
    "datasets = hf.get_datasets()\n",
    "print(datasets)\n",
    "\n",
    "options = {\"dataset\": \"conus2_domain\"}\n",
    "variables = hf.get_variables(options)\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6480c-dedd-49a4-bf0f-bc4cbda27ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
