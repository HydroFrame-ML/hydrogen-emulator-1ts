name: UpperEel_box.wy2003
log_location: /home/ga6/workspace/model_training
model_type: convnext # fixed for now
optimizer: adam # fixed for now
loss: mse # fixed for now
n_epochs: 5 # small for testing
batch_size: 128 # small for testing
lr: 0.001
num_workers: 16
dtype: float64
device: cuda:0
set_seed: true

data_def:
  train_data_location: /scratch/network/reedmm/1ts_training/Upper_Eel_box/
  validation_data_location: /scratch/network/reedmm/1ts_training/Upper_Eel_box/
  test_data_location: /scratch/network/reedmm/1ts_training/Upper_Eel_box/
  parameters:
    - [alpha, 0]
    - [n, 0]
    - [slope_x, 0]
    - [slope_y, 0]
    - [perm_x, 0]
    - [perm_y, 0]
    - [perm_z, 0]
    - [porosity, 0]
    - [mannings, 0]
    - [specific_storage, 0]
    - [sres, 0]
  patch_size_x: 64
  patch_size_y: 62
  overlap_x: 0
  overlap_y: 0
  n_evaptrans: 5
  shuffle: False

model_def:
  in_channels: 98 # Number of input channels from state_data
  out_channels: 10 # Number of output channels (depth layers)
  kernel_size: 5 # Kernel size for the convolutional layers
  bottleneck_dim: 128
  hidden_dim: 1024 # Number of filters in the convolutional layers
  depth: 1 # Number of resnet blocks

tensorboard:
  enabled: true
  log_hyperparams: true
  log_model_graph: true
  log_images: true
  log_frequency: 5  # Log images every 5 epochs
  max_images: 3

callbacks:
  # Early stopping
  early_stopping:
    enabled: true
    monitor: 'val_loss'
    patience: 15
    min_delta: 1e-6
    mode: 'min'
    restore_best_weights: true
  
  # Model checkpointing
  model_checkpoint:
    enabled: false
    monitor: 'val_loss'
    save_best_only: true
    save_weights_only: false
    mode: 'min'
    save_top_k: 3
    verbose: true
  
  # Learning rate scheduling
  lr_scheduler:
    enabled: true
    type: 'ReduceLROnPlateau'
    mode: 'min'
    factor: 0.5
    patience: 3
    min_lr: 1e-7
    verbose: true
  
  # Gradient clipping
  gradient_clipping:
    enabled: true
    max_norm: 1.0
    norm_type: 2.0

